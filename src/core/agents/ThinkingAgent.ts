import { BaseAgent } from './Agent';
import { Action, MessageAction } from '../events/Action';
import { Observation } from '../events/Observation';
import { EventStream } from '../events/EventStream';
import { LLMProvider, ChatMessage } from '../llm/LLMProvider';

/**
 * Agent specialized for thinking and reasoning
 */
export class ThinkingAgent extends BaseAgent {
  private thoughts: string[] = [];
  
  constructor(eventStream: EventStream, llmProvider: LLMProvider) {
    super(eventStream, llmProvider);
    this.systemMessage = `You are a thinking agent that helps analyze problems and generate insights.
Your role is to think deeply about problems, break them down into components, and provide structured analysis.
When you receive information, carefully analyze it and provide your thoughts in a clear, structured format.
Focus on:
1. Understanding the core problem
2. Identifying key components and relationships
3. Generating multiple perspectives or approaches
4. Evaluating trade-offs between different options
5. Providing clear recommendations based on your analysis

Always be thorough, logical, and consider multiple viewpoints before reaching conclusions.`;
  }
  
  /**
   * Process an observation and generate a thinking response
   * @param observation The observation to process
   * @returns A message action with the thinking response
   */
  async process(observation: Observation): Promise<Action> {
    // Create messages for the LLM
    const messages: ChatMessage[] = [
      { role: 'system', content: this.getSystemMessage() }
    ];
    
    // Add previous thoughts for context
    if (this.thoughts.length > 0) {
      messages.push({
        role: 'system',
        content: `Previous thoughts:\n${this.thoughts.join('\n\n')}`
      });
    }
    
    // Add the current observation
    messages.push({
      role: 'user',
      content: `Please analyze the following information and provide your thoughts:\n${JSON.stringify(observation)}`
    });
    
    // Generate a response using the LLM
    const response = await this.llmProvider.generateChatCompletion(messages);
    
    // Store the thought
    this.thoughts.push(response.content);
    
    // Limit the number of stored thoughts
    if (this.thoughts.length > 10) {
      this.thoughts = this.thoughts.slice(this.thoughts.length - 10);
    }
    
    // Return a message action with the thinking response
    return new MessageAction(response.content, this.id);
  }
  
  /**
   * Reset the agent's state
   */
  reset(): void {
    this.thoughts = [];
  }
  
  /**
   * Get all thoughts generated by the agent
   * @returns Array of thoughts
   */
  getThoughts(): string[] {
    return [...this.thoughts];
  }
  
  /**
   * Get a summary of the agent's thoughts
   * @returns A summary of the thoughts
   */
  async getThoughtSummary(): Promise<string> {
    if (this.thoughts.length === 0) {
      return 'No thoughts generated yet.';
    }
    
    const messages: ChatMessage[] = [
      { role: 'system', content: 'Summarize the following thoughts into a concise summary:' },
      { role: 'user', content: this.thoughts.join('\n\n') }
    ];
    
    const response = await this.llmProvider.generateChatCompletion(messages);
    return response.content;
  }
}